(window.webpackJsonp=window.webpackJsonp||[]).push([[20],{380:function(v,_,a){"use strict";a.r(_);var e=a(42),s=Object(e.a)({},(function(){var v=this,_=v.$createElement,a=v._self._c||_;return a("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[a("h1",{attrs:{id:"后端开发知识体系"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#后端开发知识体系"}},[v._v("#")]),v._v(" 后端开发知识体系")]),v._v(" "),a("h2",{attrs:{id:"rpc"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#rpc"}},[v._v("#")]),v._v(" RPC")]),v._v(" "),a("p",[v._v("RPC 就是让业务像调用本地函数一样去使用远程计算机提供的服务。发起 RPC 调用请求的那一方叫做调用方，被调用的一方叫做服务提供方。")]),v._v(" "),a("p",[v._v("RPC 的核心有两点：")]),v._v(" "),a("ul",[a("li",[v._v("数据序列化框架")]),v._v(" "),a("li",[v._v("网络传输协议")])]),v._v(" "),a("p",[v._v("传输协议可以直接用 HTTP 协议，也可以基于 TCP 定制私有协议。")]),v._v(" "),a("p",[v._v("序列化/反序列化的方法有很多，各语言都有自带方法序列化为二进制。但事情远没有那么简单，要考虑到性能、压缩率、跨语言、向下兼容、大小端等。所以出现了一些序列化框架：")]),v._v(" "),a("ul",[a("li",[v._v("Protobuf")]),v._v(" "),a("li",[v._v("Hessian")]),v._v(" "),a("li",[v._v("Thrift")]),v._v(" "),a("li",[v._v("Avro")]),v._v(" "),a("li",[v._v("等等")])]),v._v(" "),a("p",[v._v("可以从以下几个角度来决定如何选择序列化框架：")]),v._v(" "),a("ul",[a("li",[v._v("序列化/反序列化的性能")]),v._v(" "),a("li",[v._v("二进制数据的体积大小，这决定了网络传输的效率")]),v._v(" "),a("li",[v._v("向下兼容，当消息格式升级后，旧版本的客户端还需要能正常使用")])]),v._v(" "),a("h2",{attrs:{id:"数据库"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据库"}},[v._v("#")]),v._v(" 数据库")]),v._v(" "),a("h3",{attrs:{id:"sql"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sql"}},[v._v("#")]),v._v(" SQL")]),v._v(" "),a("p",[v._v("SQL 基于关系代数，所以只能用于 RDBMS。SQL 是一个标准，目前常用的是 SQL 92 和 SQL 99。SQL 分为 DDL、DML、DCL、TCL，水还是很深的，最常用的 select 语句并不属于这四者，而是属于 DQL。")]),v._v(" "),a("h3",{attrs:{id:"索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#索引"}},[v._v("#")]),v._v(" 索引")]),v._v(" "),a("p",[v._v("索引可以提高数据查询的效率，内部实现有哈希表、有序数组、搜索树、跳表。")]),v._v(" "),a("p",[v._v("哈希表只适用于等值查询的场景 (如 Redis、Memcached)，还需要解决哈希冲突的问题。")]),v._v(" "),a("p",[v._v("有序数组通过二分查找对应的值，适用于范围查询的场景 O(logN)，更新/插入数据效率很低 O(N)。因此更适用于不会再变化的静态数据。")]),v._v(" "),a("p",[v._v("搜索树又分为：二叉搜索树、N叉搜索树、红黑树、B+树、LSM。")]),v._v(" "),a("h3",{attrs:{id:"kv-数据库"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#kv-数据库"}},[v._v("#")]),v._v(" KV 数据库")]),v._v(" "),a("p",[v._v("【存什么数据】键值数据库中，数据一定是以 Key-Value 的形式存储的，Key 一定是 String 类型，而 Value 不一定。")]),v._v(" "),a("ul",[a("li",[v._v("Redis 的 Value 可以是 String、哈希表、列表、集合等类型")]),v._v(" "),a("li",[v._v("Memcached 的 Value 只能是 String 类型")])]),v._v(" "),a("p",[v._v("【存在哪里】数据可以存在内存或外存中。")]),v._v(" "),a("ul",[a("li",[v._v("Redis、Memcached 都是放在内存里面；速度很快，但数据有丢失风险；适用于缓存等数据丢失不敏感场景；")]),v._v(" "),a("li",[v._v("放在外存里面")]),v._v(" "),a("li",[v._v("另一种方案是购买非易失性内存")])]),v._v(" "),a("p",[v._v("【如何访问】单机型数据库还是联机型数据库？")]),v._v(" "),a("ul",[a("li",[v._v("RocksDB 是单机型数据库，提供动态库文件给业务访问")]),v._v(" "),a("li",[v._v("Memcached 和 Redis 是联机型数据库，通过网络协议来访问")])]),v._v(" "),a("p",[v._v("【如何根据 key 找到 value】这就涉及到索引的概念，索引的常见实现包括哈希表、B+树、跳表、字典树。")]),v._v(" "),a("ul",[a("li",[v._v("Redis、Memcached 采用哈希表")]),v._v(" "),a("li",[v._v("RocksDB 采用跳表")])]),v._v(" "),a("h4",{attrs:{id:"redis-的哈希表索引"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#redis-的哈希表索引"}},[v._v("#")]),v._v(" Redis 的哈希表索引")]),v._v(" "),a("p",[v._v("作为 KV 数据库，Redis 使用哈希表实现 Key 到 Value 的快速索引，使用拉链法解决哈希冲突。")]),v._v(" "),a("p",[v._v("【rehash】拉链法中的链表过长，会导致性能/吞吐量下降。为了解决这个问题，Redis 使用了 rehash 的机制。内部有 hash1 和 hash2 两个哈希表，当 hash1 的链表过长时，为 hash2 分配两倍的空间，同时将 hash1 的数据拷贝到 hash2。通过两个哈希表轮换使用，实现了哈希表的扩容，减少冲突/减少链表长度。")]),v._v(" "),a("p",[v._v("【渐进式rehash】rehash 涉及到哈希表的整体复制，会导致线程阻塞/单次响应时间长。为了解决这个问题，Redis 采用渐进式 rehash 机制，将大量数据拷贝操作分摊到每次请求中。")]),v._v(" "),a("h4",{attrs:{id:"redis-的单线程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#redis-的单线程"}},[v._v("#")]),v._v(" Redis 的单线程")]),v._v(" "),a("p",[v._v("我们平时说 Redis 单线程，指的是其网络 I/O 和数据读写操作是放在同一个线程里面的。通过多路复用，保证单线程下也能实现高吞吐量。")]),v._v(" "),a("p",[v._v("其内部是基于非阻塞式 Socket + select/epoll 实现的。")]),v._v(" "),a("h3",{attrs:{id:"聚合查询"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#聚合查询"}},[v._v("#")]),v._v(" 聚合查询")]),v._v(" "),a("p",[v._v("在 SQL 中，通过 group by + 聚合函数来实现。")]),v._v(" "),a("p",[v._v("在 MongoDB 中，通过 Aggregation Pipeline 来实现，一个 Pipeline 包含多个 stage。")]),v._v(" "),a("h3",{attrs:{id:"高可用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#高可用"}},[v._v("#")]),v._v(" 高可用")]),v._v(" "),a("p",[v._v("MongoDB 通过"),a("a",{attrs:{href:"https://docs.mongodb.com/manual/replication/",target:"_blank",rel:"noopener noreferrer"}},[v._v("副本集"),a("OutboundLink")],1),v._v("的方式，当主节点挂了，从节点会进行选举选出一个新的主节点。增加副本集的节点数量可以提高读性能，不能提高写性能。")])])}),[],!1,null,null,null);_.default=s.exports}}]);